\documentclass[11pt]{article}

    \usepackage[breakable]{tcolorbox}
    \usepackage{parskip} % Stop auto-indenting (to mimic markdown behaviour)
    

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % Maintain compatibility with old templates. Remove in nbconvert 6.0
    \let\Oldincludegraphics\includegraphics
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionFormat{nocaption}{}
    \captionsetup{format=nocaption,aboveskip=0pt,belowskip=0pt}

    \usepackage{float}
    \floatplacement{figure}{H} % forces figures to be placed at the correct location
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro

    \usepackage{iftex}
    \ifPDFTeX
        \usepackage[T1]{fontenc}
        \IfFileExists{alphabeta.sty}{
              \usepackage{alphabeta}
          }{
              \usepackage[mathletters]{ucs}
              \usepackage[utf8x]{inputenc}
          }
    \else
        \usepackage{fontspec}
        \usepackage{unicode-math}
    \fi

    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics
                         % to support a larger range
    \makeatletter % fix for old versions of grffile with XeLaTeX
    \@ifpackagelater{grffile}{2019/11/01}
    {
      % Do nothing on new versions
    }
    {
      \def\Gread@@xetex#1{%
        \IfFileExists{"\Gin@base".bb}%
        {\Gread@eps{\Gin@base.bb}}%
        {\Gread@@xetex@aux#1}%
      }
    }
    \makeatother
    \usepackage[Export]{adjustbox} % Used to constrain images to a maximum size
    \adjustboxset{max size={0.9\linewidth}{0.9\paperheight}}

    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    % The default LaTeX title has an obnoxious amount of whitespace. By default,
    % titling removes some of it. It also provides customization options.
    \usepackage{titling}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage{array}     % table support for pandoc >= 2.11.3
    \usepackage{calc}      % table minipage width calculation for pandoc >= 2.11.1
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    \usepackage{mathrsfs}
    

    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}
    \definecolor{ansi-default-inverse-fg}{HTML}{FFFFFF}
    \definecolor{ansi-default-inverse-bg}{HTML}{000000}

    % common color for the border for error outputs.
    \definecolor{outerrorbackground}{HTML}{FFDFDF}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}

    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}


    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatibility definitions
    \def\gt{>}
    \def\lt{<}
    \let\Oldtex\TeX
    \let\Oldlatex\LaTeX
    \renewcommand{\TeX}{\textrm{\Oldtex}}
    \renewcommand{\LaTeX}{\textrm{\Oldlatex}}
    % Document parameters
    % Document title
    \title{ReportLovisaFinalDraft}
    
    
    
    
    
% Pygments definitions
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\@namedef{PY@tok@w}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\@namedef{PY@tok@c}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cp}{\def\PY@tc##1{\textcolor[rgb]{0.61,0.40,0.00}{##1}}}
\@namedef{PY@tok@k}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kp}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kt}{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\@namedef{PY@tok@o}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@ow}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\@namedef{PY@tok@nb}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@nf}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@nc}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@nn}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@ne}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.80,0.25,0.22}{##1}}}
\@namedef{PY@tok@nv}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@no}{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\@namedef{PY@tok@nl}{\def\PY@tc##1{\textcolor[rgb]{0.46,0.46,0.00}{##1}}}
\@namedef{PY@tok@ni}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.44,0.44,0.44}{##1}}}
\@namedef{PY@tok@na}{\def\PY@tc##1{\textcolor[rgb]{0.41,0.47,0.13}{##1}}}
\@namedef{PY@tok@nt}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@nd}{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\@namedef{PY@tok@s}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sd}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@si}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.64,0.35,0.47}{##1}}}
\@namedef{PY@tok@se}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.36,0.12}{##1}}}
\@namedef{PY@tok@sr}{\def\PY@tc##1{\textcolor[rgb]{0.64,0.35,0.47}{##1}}}
\@namedef{PY@tok@ss}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@sx}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@m}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@gh}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\@namedef{PY@tok@gu}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\@namedef{PY@tok@gd}{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\@namedef{PY@tok@gi}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.52,0.00}{##1}}}
\@namedef{PY@tok@gr}{\def\PY@tc##1{\textcolor[rgb]{0.89,0.00,0.00}{##1}}}
\@namedef{PY@tok@ge}{\let\PY@it=\textit}
\@namedef{PY@tok@gs}{\let\PY@bf=\textbf}
\@namedef{PY@tok@gp}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\@namedef{PY@tok@go}{\def\PY@tc##1{\textcolor[rgb]{0.44,0.44,0.44}{##1}}}
\@namedef{PY@tok@gt}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\@namedef{PY@tok@err}{\def\PY@bc##1{{\setlength{\fboxsep}{\string -\fboxrule}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}}
\@namedef{PY@tok@kc}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kd}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kn}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kr}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@bp}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@fm}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@vc}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vg}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vi}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vm}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@sa}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sb}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sc}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@dl}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@s2}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sh}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@s1}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@mb}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mf}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mh}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mi}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@il}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mo}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@ch}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cm}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cpf}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@c1}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cs}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % For linebreaks inside Verbatim environment from package fancyvrb.
    \makeatletter
        \newbox\Wrappedcontinuationbox
        \newbox\Wrappedvisiblespacebox
        \newcommand*\Wrappedvisiblespace {\textcolor{red}{\textvisiblespace}}
        \newcommand*\Wrappedcontinuationsymbol {\textcolor{red}{\llap{\tiny$\m@th\hookrightarrow$}}}
        \newcommand*\Wrappedcontinuationindent {3ex }
        \newcommand*\Wrappedafterbreak {\kern\Wrappedcontinuationindent\copy\Wrappedcontinuationbox}
        % Take advantage of the already applied Pygments mark-up to insert
        % potential linebreaks for TeX processing.
        %        {, <, #, %, $, ' and ": go to next line.
        %        _, }, ^, &, >, - and ~: stay at end of broken line.
        % Use of \textquotesingle for straight quote.
        \newcommand*\Wrappedbreaksatspecials {%
            \def\PYGZus{\discretionary{\char`\_}{\Wrappedafterbreak}{\char`\_}}%
            \def\PYGZob{\discretionary{}{\Wrappedafterbreak\char`\{}{\char`\{}}%
            \def\PYGZcb{\discretionary{\char`\}}{\Wrappedafterbreak}{\char`\}}}%
            \def\PYGZca{\discretionary{\char`\^}{\Wrappedafterbreak}{\char`\^}}%
            \def\PYGZam{\discretionary{\char`\&}{\Wrappedafterbreak}{\char`\&}}%
            \def\PYGZlt{\discretionary{}{\Wrappedafterbreak\char`\<}{\char`\<}}%
            \def\PYGZgt{\discretionary{\char`\>}{\Wrappedafterbreak}{\char`\>}}%
            \def\PYGZsh{\discretionary{}{\Wrappedafterbreak\char`\#}{\char`\#}}%
            \def\PYGZpc{\discretionary{}{\Wrappedafterbreak\char`\%}{\char`\%}}%
            \def\PYGZdl{\discretionary{}{\Wrappedafterbreak\char`\$}{\char`\$}}%
            \def\PYGZhy{\discretionary{\char`\-}{\Wrappedafterbreak}{\char`\-}}%
            \def\PYGZsq{\discretionary{}{\Wrappedafterbreak\textquotesingle}{\textquotesingle}}%
            \def\PYGZdq{\discretionary{}{\Wrappedafterbreak\char`\"}{\char`\"}}%
            \def\PYGZti{\discretionary{\char`\~}{\Wrappedafterbreak}{\char`\~}}%
        }
        % Some characters . , ; ? ! / are not pygmentized.
        % This macro makes them "active" and they will insert potential linebreaks
        \newcommand*\Wrappedbreaksatpunct {%
            \lccode`\~`\.\lowercase{\def~}{\discretionary{\hbox{\char`\.}}{\Wrappedafterbreak}{\hbox{\char`\.}}}%
            \lccode`\~`\,\lowercase{\def~}{\discretionary{\hbox{\char`\,}}{\Wrappedafterbreak}{\hbox{\char`\,}}}%
            \lccode`\~`\;\lowercase{\def~}{\discretionary{\hbox{\char`\;}}{\Wrappedafterbreak}{\hbox{\char`\;}}}%
            \lccode`\~`\:\lowercase{\def~}{\discretionary{\hbox{\char`\:}}{\Wrappedafterbreak}{\hbox{\char`\:}}}%
            \lccode`\~`\?\lowercase{\def~}{\discretionary{\hbox{\char`\?}}{\Wrappedafterbreak}{\hbox{\char`\?}}}%
            \lccode`\~`\!\lowercase{\def~}{\discretionary{\hbox{\char`\!}}{\Wrappedafterbreak}{\hbox{\char`\!}}}%
            \lccode`\~`\/\lowercase{\def~}{\discretionary{\hbox{\char`\/}}{\Wrappedafterbreak}{\hbox{\char`\/}}}%
            \catcode`\.\active
            \catcode`\,\active
            \catcode`\;\active
            \catcode`\:\active
            \catcode`\?\active
            \catcode`\!\active
            \catcode`\/\active
            \lccode`\~`\~
        }
    \makeatother

    \let\OriginalVerbatim=\Verbatim
    \makeatletter
    \renewcommand{\Verbatim}[1][1]{%
        %\parskip\z@skip
        \sbox\Wrappedcontinuationbox {\Wrappedcontinuationsymbol}%
        \sbox\Wrappedvisiblespacebox {\FV@SetupFont\Wrappedvisiblespace}%
        \def\FancyVerbFormatLine ##1{\hsize\linewidth
            \vtop{\raggedright\hyphenpenalty\z@\exhyphenpenalty\z@
                \doublehyphendemerits\z@\finalhyphendemerits\z@
                \strut ##1\strut}%
        }%
        % If the linebreak is at a space, the latter will be displayed as visible
        % space at end of first line, and a continuation symbol starts next line.
        % Stretch/shrink are however usually zero for typewriter font.
        \def\FV@Space {%
            \nobreak\hskip\z@ plus\fontdimen3\font minus\fontdimen4\font
            \discretionary{\copy\Wrappedvisiblespacebox}{\Wrappedafterbreak}
            {\kern\fontdimen2\font}%
        }%

        % Allow breaks at special characters using \PYG... macros.
        \Wrappedbreaksatspecials
        % Breaks at punctuation characters . , ; ? ! and / need catcode=\active
        \OriginalVerbatim[#1,codes*=\Wrappedbreaksatpunct]%
    }
    \makeatother

    % Exact colors from NB
    \definecolor{incolor}{HTML}{303F9F}
    \definecolor{outcolor}{HTML}{D84315}
    \definecolor{cellborder}{HTML}{CFCFCF}
    \definecolor{cellbackground}{HTML}{F7F7F7}

    % prompt
    \makeatletter
    \newcommand{\boxspacing}{\kern\kvtcb@left@rule\kern\kvtcb@boxsep}
    \makeatother
    \newcommand{\prompt}[4]{
        {\ttfamily\llap{{\color{#2}[#3]:\hspace{3pt}#4}}\vspace{-\baselineskip}}
    }
    

    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

\begin{document}
    
    \maketitle
    
    

    
    \hypertarget{abstract}{%
\section{Abstract}\label{abstract}}

Arctic new particle formation is an import source of cloud condensation
nuclei which in turn affects cloud properties. Insights into the drivers
of new particle formation in a changing Arctic climate are important, as
clouds in this region contribute to further warming of an already
vulnerable environment. Sea ice extent in the Greenland and Barents Sea
has been observed to be anticorrelated with new particle formation event
frequency at the Zeppelin Observatory at Svalbard, but the underlying
processes are complex, and the question is whether this continues to
hold true for more recent years. In this work, DMPS and CPC data from
Zeppelin between 2010-2020 as well as satellite data on sea ice and
chlorophyll concentration was used to evaluate this. The correlation
between new particle formation and sea ice concentration is
investigated, and different methods are tested to identify a suitable
indicator for detection of new particle formation events in the size
distribution data. K-means cluster analysis was chosen in order to
compare with the results from 2000-2010 obtained in a previous study.
K-means clustering was used on the data to partition it into distinct
and separate clusters based on the shape of the normalized aerosol
particle number size distributions. Our results indicate weak trends in
the May-June-July occurence for all clusters between 2010 and 2020.
Furthermore, the results suggest that there is no correlation between
the annual new particle formation frequency and sea ice concentration in
the Greenland and Barents Sea for the years 2010-2017, which differs
from previous observations at Zeppelin between 2000-2010. Further
investigations utilizing for example air mass trajectory analysis and
suitable new particle formation indicators are needed to obtain a more
complete understanding of the complex interplay between new particle
formation drivers.

    \hypertarget{acknowledgements}{%
\section{Acknowledgements}\label{acknowledgements}}

First and foremost, I would like to acknowledge the providers of the
data sets OSI-SAF consortium (sea ice data) and OBS-ESACCI-OC for
chlorophyll data, and the Norwegian Polar Institute (NPI) for running
the Zeppelin station and EBAS for managing the database.

I collaborated with Kei Tsuruhara and our supervisor Dominic
Heslin-Rees. I am very thankful to be part of this team, it has been
inspiring (and fun!) to work with both of you. In this report Kei has
produced the sea ice data (it was not easy to work with that dataset!),
Dominic provided the DMPS and CPC data as well as some functions to read
in and do the basic preparation of data. Other than that, I have
received tremendous amount of help and advice while learning Python (and
data analysis in general) from especially Dominic but also from other
course instructors. Thanks Paul Zieger for your enthusiasm and great
advice on things to look more into. Thanks to Linn Karlsson whose work
in a previous version of this course happened to include a great
function to integrate log-normal distributions.

    \hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

The Arctic has experienced much faster rates of warming than other parts
of the globe. The response to increased temperature in the Arctic
environment is manyfold and implies drastic changes to of the whole
environment and ecosystems. Drastic reductions in sea ice cover during
the summertime is one key manifestation of the changes taking place
(Perovich et al., 2018). The Arctic becoming more biologically
productive, and the increased emissions of aerosol precursor gases, is
another example of changes taking place (Gal√≠ et al.~2019).

The Arctic annual cycle of airborne particulate matter properties is
largely the result of variations in meteorological conditions and
dominating sources (Tunved et al.~2013). During polar night, ocean and
air circulation patterns imply an influx of anthropogenic pollutants,
and the aerosol size distribution is dominated by accumulation mode
particles. In combination with the Arctic wintertime meteorological
conditions, this leads to the formation of a persistent Arctic haze. As
the sun gradually returns, the circulation and airmass transport
patterns change and restrict the anthropogenic pollution inflow so
natural sources dominate. Formation of low-level clouds during
summertime, which leads to removal of accumulation mode particles by wet
scavenging, marks the end of the Arctic Haze period. Consequently, the
composition, properties, and size distribution of Arctic aerosol
particles change. The lower aerosol loading and increased availability
of sunlight promotes photochemistry which results in a summertime peak
of aerosol particles smaller than 100 nm (Schmale \& Baccarini, 2021).

New particle formation (NPF) plays an important role in the Arctic
radiation budget as the newly formed aerosol particles may grow to cloud
condensation nuclei's (CCNs), and subsequently activate into cloud
droplets. In short, NPF at Svalbard has been described as the result of
photo-oxidation of volatile gases emitted from for example the ocean,
soil and snow into low-volatility aerosol precursors (Beck et al.,
2021). When aerosol loadings and thus condensation sinks are low, the
low volatile gases may undergo self-nucleation to form new particles.
Cloud formation may during summer in the high Arctic be CCN limited
(Mauritsen et al., 2011), and the production of particles from NPF
events has in global modelling studies been shown to contribute to the
majority of CCNs in the Arctic (Gordon et al., 2017). Low-level clouds
influence the Arctic radiation budget, and likely contributes to
amplified warming (Schmale \& Baccarini, 2021), which makes studies of
NPF event frequency and drivers important.

At the Zeppelin Observatory on Svalbard, long-term measurements have
been conducted to monitor the properties of aerosol particles. Long-term
measurements are valuable to monitor the changes taking place in a
sensitive Arctic environment. Data from eleven years of DMPS
measurements (2000-2010) at the Zeppelin station have been used to
investigate the hypothesis that Arctic sea ice reduction in the
Greenland and Barents Sea leads to an increase in the frequency of NPF
events at Zeppelin (Dall'Osto et al.~2017). The question this project
makes an attempt to answer is whether this is a causal effect, if this
hold true for subsequent years and if trends in proxies for the
productivity of oceans might be driving NPF as well. Another aim is to
partly reproduce the Dall'Osto paper for a later time period by applying
a similar methodology with regards to NPF identification in the DMPS
data, as well as to investigate other possibilities for NPF
identification. We (as a group) use satellite data on sea ice and
chlorophyll concentration and aerosol size distribution and number
concentration data from Zeppelin. This report focuses on the analysis of
the DMPS and CPC data, with some use of annual sea ice concentration
data for the Greenland and Barents Sea.

    \hypertarget{method}{%
\section{Method}\label{method}}

\hypertarget{datsets}{%
\subsection{Datsets}\label{datsets}}

The Arctic measurement station Zeppelin Observatory is located on
Svalbard, which is situated between the Greenland and Barents Sea. We
have used level 2 Differential Mobility Particle Sizer (DMPS) and data
from two different Condensation particle counters (CPC) from the
Zeppelin Observatory, provided by our supervisor Dominic Heslin-Rees,
and satellite retrieved sea ice concentration from OSI-SAF and satellite
chlorophyll observations OBS-ESACCI-OC. The DMPS and CPC data encompass
the years 2010-2020 with overall high data coverage, with a 30 min
resolution. Starting date for the DMPS and CPC data was 2010-08-03 and
the end date was 2020-12-31 with a total data coverage of 66\% ( = 60439
h/912996 h) in terms of hours. Data coverage is therefore something that
needs to be accounted for when calulating the NPF frequency. The
satellite data was processed by Kei and DMPS and CPC data is the focus
of this report.

The DMPS measures the particle number size distributions for particles
smaller than 1000 nm. The DMPS scans over different sizes and measures
the number concentration (\#/cm\(^3\)) in each size interval, or bin.
The size range covered by the DMPS is 5-708 nm. The output is in the
form of log normal particle concentration (i.e.~dn/dlogDp) which
accounts for the difference bin bin width.

A CPC counts particles in the sub micrometer range and provides the
particle number concentration (\#/cm\(^3\)). Data from two different
CPCs was used, the UFCPC (ultrafine CPC) and the CPC 3010. The UFCPC has
a particle diameter threshold at 3 nm which in comparision with the
CPC3010 whose lower threshold is at 10 nm.

    \hypertarget{import-packages}{%
\subsection{Import packages}\label{import-packages}}

And make sure that functions are auto-updated.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{1}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{DMPS\PYZus{}functions} \PY{k}{as} \PY{n+nn}{fu}
\PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
\PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
\PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
\PY{k+kn}{import} \PY{n+nn}{datetime} 
\PY{k+kn}{import} \PY{n+nn}{seaborn} \PY{k}{as} \PY{n+nn}{sns}
\PY{k+kn}{import} \PY{n+nn}{scipy} \PY{k}{as} \PY{n+nn}{sc}
\PY{k+kn}{import} \PY{n+nn}{glob} 
\PY{k+kn}{import} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{metrics} \PY{k}{as} \PY{n+nn}{skm}
\PY{k+kn}{from} \PY{n+nn}{sklearn} \PY{k+kn}{import} \PY{n}{metrics}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{metrics}\PY{n+nn}{.}\PY{n+nn}{pairwise} \PY{k+kn}{import} \PY{n}{pairwise\PYZus{}distances}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{cluster} \PY{k+kn}{import} \PY{n}{KMeans}
\PY{k+kn}{import} \PY{n+nn}{scipy}\PY{n+nn}{.}\PY{n+nn}{stats} \PY{k}{as} \PY{n+nn}{st}
\PY{k+kn}{import} \PY{n+nn}{seaborn} \PY{k}{as} \PY{n+nn}{sns}
\PY{k+kn}{from} \PY{n+nn}{matplotlib} \PY{k+kn}{import} \PY{n}{cm}

\PY{c+c1}{\PYZsh{} Auto\PYZhy{}update the functions. Useful if the functions have been altered. }
\PY{o}{\PYZpc{}}\PY{n}{load\PYZus{}ext} \PY{n}{autoreload}
\PY{o}{\PYZpc{}}\PY{n}{autoreload} \PY{l+m+mi}{2}

\PY{n}{plt}\PY{o}{.}\PY{n}{rcParams}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{font.size}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{12}\PY{l+s+s1}{\PYZsq{}}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{2}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Defining the path containg all DMPS data}
\PY{n}{path} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{C:}\PY{l+s+se}{\PYZbs{}\PYZbs{}}\PY{l+s+s1}{Users}\PY{l+s+se}{\PYZbs{}\PYZbs{}}\PY{l+s+s1}{Lovisa}\PY{l+s+se}{\PYZbs{}\PYZbs{}}\PY{l+s+s1}{Documents}\PY{l+s+se}{\PYZbs{}\PYZbs{}}\PY{l+s+s1}{Courses II}\PY{l+s+se}{\PYZbs{}\PYZbs{}}\PY{l+s+s1}{E\PYZus{}science\PYZus{}tools HT22}\PY{l+s+se}{\PYZbs{}\PYZbs{}}\PY{l+s+s1}{Project}\PY{l+s+se}{\PYZbs{}\PYZbs{}}\PY{l+s+s1}{DATA\PYZus{}ZEP\PYZus{}2010to2020}\PY{l+s+se}{\PYZbs{}\PYZbs{}}\PY{l+s+s1}{\PYZsq{}}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{3}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Using glob to import the files in the specified path}
\PY{n}{fu}\PY{o}{.}\PY{n}{importData}\PY{p}{(}\PY{n}{path}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    Loading each year of 30 min resolution DMPS data into a dataframe and
create a list containing all dataframes. Column headings are added, and
data flagged as invalid is removed.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{4}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{DFs\PYZus{}DMPS} \PY{o}{=} \PY{n}{fu}\PY{o}{.}\PY{n}{load\PYZus{}and\PYZus{}append\PYZus{}DMPS}\PY{p}{(}\PY{n}{path}\PY{p}{,} 
                             \PY{n}{name\PYZus{}in\PYZus{}file}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DMPS}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{concatenate-dmps-data}{%
\subsection{Concatenate DMPS data}\label{concatenate-dmps-data}}

The DMPS data comes in several files and must be concatenated into a
common dateframe, and unnecessary columns are dropped.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{5}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{df\PYZus{}DMPS} \PY{o}{=} \PY{n}{fu}\PY{o}{.}\PY{n}{concat\PYZus{}df\PYZus{}DMPS}\PY{p}{(}\PY{n}{DFs\PYZus{}DMPS}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    Useful variables are defined using column headings renamed to ease
calling of specific columns.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{6}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Get a list with the DMPS bin column names as strings and floats to call column in dataframe and for calculations.}
\PY{n}{bin\PYZus{}col\PYZus{}list} \PY{o}{=} \PY{n}{fu}\PY{o}{.}\PY{n}{get\PYZus{}bin\PYZus{}column\PYZus{}string\PYZus{}list}\PY{p}{(}\PY{p}{)}
\PY{n}{bin\PYZus{}cols} \PY{o}{=} \PY{n}{fu}\PY{o}{.}\PY{n}{get\PYZus{}bins}\PY{p}{(}\PY{n}{bin\PYZus{}col\PYZus{}list}\PY{p}{)}
\PY{n}{bin\PYZus{}cols} \PY{o}{=} \PY{p}{[}\PY{n+nb}{float}\PY{p}{(}\PY{n}{x}\PY{p}{)} \PY{k}{for} \PY{n}{x} \PY{o+ow}{in} \PY{n}{bin\PYZus{}cols}\PY{p}{]}

\PY{c+c1}{\PYZsh{} Rename the column headings for midpoint diameters to numeric values with less decimals.}
\PY{n}{df\PYZus{}DMPS} \PY{o}{=} \PY{n}{fu}\PY{o}{.}\PY{n}{renameDpColumns}\PY{p}{(}\PY{n}{df\PYZus{}DMPS}\PY{p}{,} \PY{n}{bin\PYZus{}col\PYZus{}list}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Make a list of all the \PYZdq{}real\PYZdq{} non\PYZhy{}rounded midpoint diameters as a list and as array.}
\PY{n}{diameterList}\PY{p}{,} \PY{n}{diameters} \PY{o}{=} \PY{n}{fu}\PY{o}{.}\PY{n}{getFloatDiameterListAndArray}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Make a list of diameters as string\PYZhy{}objects}
\PY{n}{diameters\PYZus{}as\PYZus{}strings} \PY{o}{=} \PY{p}{[}\PY{n+nb}{str}\PY{p}{(}\PY{n}{x}\PY{p}{)} \PY{k}{for} \PY{n}{x} \PY{o+ow}{in} \PY{n}{diameters}\PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{resampling-to-hourly-averages}{%
\subsection{Resampling to hourly
averages}\label{resampling-to-hourly-averages}}

The function \texttt{resample} was used to convert the 30 min DMPS
particle size distribution data to a dataframe containing the 1 hour
average. The python function \texttt{resample} fills the gaps in the
data by adding rows for gap days/months/hours with NaN-values to get a
continous dataset. Because of this, rows containing only NaN values are
dropped.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{7}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{df\PYZus{}hourly\PYZus{}2010\PYZus{}2020\PYZus{}mean}  \PY{o}{=} \PY{n}{df\PYZus{}DMPS}\PY{o}{.}\PY{n}{resample}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{H}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}
\PY{n}{df\PYZus{}hourly\PYZus{}2010\PYZus{}2020\PYZus{}mean}  \PY{o}{=} \PY{n}{df\PYZus{}hourly\PYZus{}2010\PYZus{}2020\PYZus{}mean}\PY{o}{.}\PY{n}{dropna}\PY{p}{(}\PY{n}{how}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{all}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    The first two columns in the dataframe contain data from two different
CPCs, i.e.~condensation particle counters which count particles and
yield the particle concentration in \#/cm\(^3\). The third colum Ntot
contains the total particles number concentration as computed by the
DMPS. The rest of the columns specify the midpoint size (nm) of the bins
for which the values indicate the log-normal distribution. The last
column contains flags indicating the validity of the data. Invalid data
was removed by the \texttt{concat\_df\_DMPS} function.

    \hypertarget{identifying-npf-events}{%
\subsection{Identifying NPF events}\label{identifying-npf-events}}

One of the aims of this report is to conduct a brief investigation of
different methods to identify NPF events. Some different methods are
tested to identify the NPF events:

\begin{itemize}
\tightlist
\item
  By calculating \(\frac{N_{D_p<X}}{N_{tot}}\)
\item
  By using K-means clustering
\item
  By calculating the difference between the UFCPC and the CPC
\end{itemize}

Below the methods are decribed in more detail.

    \hypertarget{method-1-using-n_d_p-xn_tot}{%
\subsubsection{\texorpdfstring{Method 1: Using
\(N_{D_P <X}/N_{tot}\)}{Method 1: Using N\_\{D\_P \textless X\}/N\_\{tot\}}}\label{method-1-using-n_d_p-xn_tot}}

The motivation to use the first metod is that in the event of NPF, there
will by a drastic increase in number concentration of particles in
smallest size bins, and the ratio of particles in the smaller bins to
larger size bins should be elevated. This requires that the total number
concentration \(N_{tot}\) is calculated in the full diameter range, and
\(N_{D_P< X}\) up to a certain diameter \(X\). \(X\) was chosen to 25 nm
to cover the full nucleation mode range (Seinfeld \& Pandis, 2008). To
do this, the log-normal distribution which is provided by the DMPS has
to be integrated. Linn Karlsson (e-Science course participant 2017)
should be acknowledged for great inspiration to the method used in this
work (Linn's method involved the use of dictionaries but here arrays are
used instead).

The \texttt{calcNtot} function calculates the particle concentration by
integrating in a given bin midpoint diameter interval \texttt{diameters}
and adds a column in the returned dataframe containing the calculated
values.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{8}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Calculate the total particle number concentration for the 1 h resolution data}
\PY{n}{df\PYZus{}hourly\PYZus{}2010\PYZus{}2020\PYZus{}mean\PYZus{}ntotCalc}  \PY{o}{=} \PY{n}{fu}\PY{o}{.}\PY{n}{calcNtot}\PY{p}{(}\PY{n}{diameters}\PY{p}{,} \PY{n}{df\PYZus{}hourly\PYZus{}2010\PYZus{}2020\PYZus{}mean}\PY{p}{,}\PY{n}{diameters\PYZus{}as\PYZus{}strings}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    In Figure 1, the result from the integration of the full size
distribution is compared to Ntot given in the DMPS data, and they appear
to be in good aggrement (slope of 1 and \(R^2\) close to 1), hence we
know that this integration method works.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{9}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{varx} \PY{o}{=} \PY{n}{df\PYZus{}hourly\PYZus{}2010\PYZus{}2020\PYZus{}mean\PYZus{}ntotCalc}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{NtotCalc}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{values}
\PY{n}{vary} \PY{o}{=} \PY{n}{df\PYZus{}hourly\PYZus{}2010\PYZus{}2020\PYZus{}mean\PYZus{}ntotCalc}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Ntot}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{values}

\PY{n}{fu}\PY{o}{.}\PY{n}{compareIntegration}\PY{p}{(}\PY{n}{varx}\PY{p}{,}\PY{n}{vary}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
R-squared: 0.999363
Intercept: 0.0445901316076629
Slope: 1.0004705430431775
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{ReportLovisaFinalDraft_files/ReportLovisaFinalDraft_21_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \textbf{Figure 1. Comparison of the integrated total particle number
concentration and the total particle number concentration given by the
DMPS.}

    \hypertarget{method-2-k-means-clustering}{%
\subsubsection{Method 2: K-means
clustering}\label{method-2-k-means-clustering}}

    The second approach to identify NPF events involves K-means clustering
(using \texttt{sklearn.cluster.Kmeans} (Pedegrosa et al., 2011)) of the
long-term DMPS dataset which is an unsupervised machine learning
algorithm. In short, unsupervised machine learning as opposed to
supervised, involves data without labels and the data is grouped based
on similarity of the data. This approach was previously deployed by
Dall'Osto et al.~(2017) to identify NPF events from size distribution
data at the Zeppelin, and therefore it is interesting to try the same
approach. Clustering of data implies grouping similar objects together
based on different features of the data. The K-means algorithm means
that the data is divided into to a user defined number of clusters
(\(k\)). The K-means algorithm starts by picking k random datapoints and
assigns them as centers of the cluster (centroids). Then the distance of
the other data points to the centroids are calculated and they are
assigned to the nearest cluster centroid. Then the process of assigning
new centroids starts over and the data is reassigned. This process is
then repeated several times until the final clusters are established.

Following the approach of Dall'Osto et al.~(2017), we cluster according
to the shape of the distribution. Prior to applying the K-means
clustering the size distribution data must therefore be normalized, and
the optimal numbers of clusters needs to be determined. By normalizing
the data, features that signify NPF events may be lost such as a high
number concetration in the nucleation mode compared to other modes.
However, clustering the non-normalized data resulted in clusters that
were deemed unreasonable.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{10}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{df3}\PY{p}{,} \PY{n}{df\PYZus{}daily\PYZus{}2010\PYZus{}2020\PYZus{}1h\PYZus{}mean\PYZus{}norm} \PY{o}{=} \PY{n}{fu}\PY{o}{.}\PY{n}{create\PYZus{}normalised\PYZus{}df}\PY{p}{(}\PY{n}{df\PYZus{}hourly\PYZus{}2010\PYZus{}2020\PYZus{}mean}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    For the hourly averaged data some endpoint columns where dropped in
order for the clustering to work reasonably. Normally particle number
concentrations are low in the end bins, and by dropping them it is
reasonable to assume that the overall size distribution shape should be
preserved. Furthermore, we are mainly focused on the smallest particles
and hence the two biggest size bins should hopefully not affect our
results as much.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{11}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{df\PYZus{}hourly\PYZus{}norm\PYZus{}dropped} \PY{o}{=} \PY{n}{df\PYZus{}daily\PYZus{}2010\PYZus{}2020\PYZus{}1h\PYZus{}mean\PYZus{}norm}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}
\PY{n}{df\PYZus{}hourly\PYZus{}norm\PYZus{}dropped} \PY{o}{=} \PY{n}{df\PYZus{}hourly\PYZus{}norm\PYZus{}dropped}\PY{o}{.}\PY{n}{drop} \PYZbs{}
                         \PY{p}{(}\PY{n}{columns}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{norm5.012}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{norm630.957}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{norm707.946}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{optimizing-the-number-of-clusters}{%
\paragraph{Optimizing the number of
clusters}\label{optimizing-the-number-of-clusters}}

    The optimal cluster number \emph{k} for K-means clustering needs to be
decided upon. This could be done using several methods. Here the inertia
method and the average silhouette score is used.

The inertia method implies calculating the mean squared distance of each
cluster to its nearest centroid. As a rule of thumb, a good clustering
model has a low inertia and low number of clusters. If \emph{k} equals
the number datapoints, the inertia equals zero, so while choosing the
optimal \emph{k} there is a trad eoff between inertia and number of
clusters. To find the optimal \emph{k} the elbow in the inertia vs \(k\)
is identified, where the increase in \emph{k} implies a slower decrease
in inertia.

The Silouette score generates a number between -1 and 1. The closer the
Silouette score is to 1, the better cluster are distinguished from each
other. A score of 0 implies that clusters are not well distinguished and
-1 that clusters are wrongly assigned. Here, the average silouette score
is computed which informs on the average separation of all clusters.
Ideally the Silouette score is calculated for individual samples as well
(out of the scope of this work) to optimize the choice of \emph{k}.

Optimization was done for varying \emph{k} between 2 and 13 clusters. In
Figure 2 the inertia and average Silhouette score are shown as a
function of the number of cluster (\emph{k}).

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{12}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{fu}\PY{o}{.}\PY{n}{optimizeClusters}\PY{p}{(}\PY{n}{df\PYZus{}hourly\PYZus{}norm\PYZus{}dropped}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{ReportLovisaFinalDraft_files/ReportLovisaFinalDraft_30_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \textbf{Figure 2. The inertia (left y-axis) and average silohouette
score (right y-axis) versus the number of clusters.}

    From the inertia method it is not straightforward to define the elbow,
where adding more clusters results in a minor decrease of inertia. It is
clear that the average silhoutette score of the clusters decrease with
increasing number of clusters.

The optimal cluster number was here decided to \emph{k} = 5, rather than
4 as inertia decrease less for each added cluster when \emph{k}
\textgreater{} 4. Six clusters did not improve the silouette score and
five clusters is preferred over seven as inertia is higher when \emph{k}
= 5.

    \hypertarget{method-3-utilizing-the-different-cpcs}{%
\paragraph{Method 3: Utilizing the different
CPCs}\label{method-3-utilizing-the-different-cpcs}}

The last method to identify the NPF events involves taking advantage of
the different detection limits of the UFCPC (3 nm) and CPC3010 (10 nm)
that were provided in the dataset, in addition to the DMPS data. Two
different approaches where tested: taking the absolute difference
between the instruments and by computing the ratio of measured
concentrations.

    \hypertarget{results}{%
\section{Results}\label{results}}

    \hypertarget{k-means-clustering}{%
\subsection{K-means clustering}\label{k-means-clustering}}

    The clustering was performed using \(k\) = 5 clusters.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{13}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Optimal cluster number }
\PY{n}{n\PYZus{}clusters} \PY{o}{=} \PY{l+m+mi}{5}

\PY{c+c1}{\PYZsh{}Perform K\PYZhy{}means clustering}
\PY{n}{silhouette\PYZus{}avg\PYZus{}1h}\PY{p}{,} \PY{n}{inertia1h}\PY{p}{,} \PY{n}{df\PYZus{}norm\PYZus{}clustered\PYZus{}1h\PYZus{}mean} \PY{o}{=} \PY{n}{fu}\PY{o}{.}\PY{n}{perform\PYZus{}clustering}\PY{p}{(}\PY{n}{df\PYZus{}hourly\PYZus{}norm\PYZus{}dropped}\PY{p}{,} \PY{n}{n\PYZus{}clusters}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Define the unique number of size distribution clusters in the sence that peak diameter is different.}
\PY{n}{clusters} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{unique}\PY{p}{(}\PY{n}{df\PYZus{}norm\PYZus{}clustered\PYZus{}1h\PYZus{}mean}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{clusters}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{values}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Check that the number of clusters resulting from the clustering procedure is equal to the variable ``n\PYZus{}clusters``, }
\PY{c+c1}{\PYZsh{} i.e. that the peak diameters of the clustered size distributions are unique. Print result.}
\PY{n}{fu}\PY{o}{.}\PY{n}{checkUniqueModeDiam}\PY{p}{(}\PY{n}{df\PYZus{}norm\PYZus{}clustered\PYZus{}1h\PYZus{}mean}\PY{p}{,}\PY{n}{n\PYZus{}clusters}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
OK! Clusters peak for different diameter when number of clusters =  5
    \end{Verbatim}

    Each hourly distribution was assigned a cluster ID during the
clustering. The mean, standard devitation, median, 10- and
90-percentiles of the clustered data were calulated for each cluster in
order to visulize the results of the clustering procedure.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{14}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{df\PYZus{}norm\PYZus{}clustered\PYZus{}1h\PYZus{}mean\PYZus{}median} \PY{o}{=} \PY{n}{df\PYZus{}norm\PYZus{}clustered\PYZus{}1h\PYZus{}mean}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{clusters}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{median}\PY{p}{(}\PY{p}{)}
\PY{n}{df\PYZus{}norm\PYZus{}clustered\PYZus{}1h\PYZus{}10q}         \PY{o}{=} \PY{n}{df\PYZus{}norm\PYZus{}clustered\PYZus{}1h\PYZus{}mean}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{clusters}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{quantile}\PY{p}{(}\PY{l+m+mf}{.1}\PY{p}{)}
\PY{n}{df\PYZus{}norm\PYZus{}clustered\PYZus{}1h\PYZus{}90q}         \PY{o}{=} \PY{n}{df\PYZus{}norm\PYZus{}clustered\PYZus{}1h\PYZus{}mean}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{clusters}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{quantile}\PY{p}{(}\PY{l+m+mf}{.9}\PY{p}{)}

\PY{n}{df\PYZus{}norm\PYZus{}clustered\PYZus{}1h\PYZus{}mean\PYZus{}mean}   \PY{o}{=} \PY{n}{df\PYZus{}norm\PYZus{}clustered\PYZus{}1h\PYZus{}mean}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{clusters}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}
\PY{n}{df\PYZus{}norm\PYZus{}clustered\PYZus{}1h\PYZus{}std}         \PY{o}{=} \PY{n}{df\PYZus{}norm\PYZus{}clustered\PYZus{}1h\PYZus{}mean}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{clusters}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    In Figure 3, the median and 10-90 percentiles (shaded area) of the
normalized and clustered size distribution data is shown. The mean is
plotted as dotted lines for comparison. From the graph it is clear that
median and mean are similar. From these results we suspect that cluster
1 and 2 may represent NPF related sizedistributions, although both 1 \&
2 are bimodal and extend to the accumulation mode. Varying the cluster
number did not remove the bimodality for the clusters whose normalized
distributions peak occurs for \(D_p\) \textless{} 30 nm. It could be
speculated that other sources of aerosols may be contributing to NPF
related clusters such as forest fires or biomass burning. Moreover,
clustering mean and median daily distributions using 5 clusters
displayed high similarity with the clusters shown below (daily
clustering is not shown here).

Comparing the results of our clustering analysis with that of Dall'Osto
et al.~(2017) and their daily mean clusters a few qualitative
observations could be made. Firstly, two of the clusters classified as
NPF indicators nucleation or bursting by Dall'Osto et al.~(2017) which
peak at 10 nm or lower, are most similar to our cluster 1 (however, in
that paper their normalized clusters were not plotted alongside each
other which make an absolute comparison difficult). These clusters also
have tails extending into the accumulation mode although the bimodality
is absent or not as pronounced in our hourly (nor daily or median)
clusters. It should also be mentioned that their third NPF indicator
cluster (nascent) partly shows similarity with our cluster 3 on the left
hand side of the peak, although our cluster 3 appears to be a
superposition of two modes and therefore we disregarded this cluster as
an indicator of NPF.

Lastly, the accumulation mode clusters (cluster 4 and 5) in our analysis
differ from the two accumulation mode clusters identified by Dall'Osto
et al.~in the sense that also display bimodality which was not the case
in their study.

There is some doubt as to whether the clustering method actually
captures the NPF events correctly. In general, it seems as though the
method works well at displaying the average seasonality of the overall
size distribution (see Figure S1 and S2 in the Supplement). At least
cluster 1 appears to be related to NPF, but additional validation is
needed.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{15}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{fu}\PY{o}{.}\PY{n}{plotClustersNormalized}\PY{p}{(}\PY{n}{df\PYZus{}norm\PYZus{}clustered\PYZus{}1h\PYZus{}mean}\PY{p}{,} \PY{n}{diameters}\PY{p}{,}
                           \PY{n}{df\PYZus{}norm\PYZus{}clustered\PYZus{}1h\PYZus{}mean\PYZus{}mean}\PY{p}{,}
                           \PY{n}{df\PYZus{}norm\PYZus{}clustered\PYZus{}1h\PYZus{}10q}\PY{p}{,}
                           \PY{n}{df\PYZus{}norm\PYZus{}clustered\PYZus{}1h\PYZus{}90q}\PY{p}{,}
                           \PY{n}{df\PYZus{}norm\PYZus{}clustered\PYZus{}1h\PYZus{}mean\PYZus{}median}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{ReportLovisaFinalDraft_files/ReportLovisaFinalDraft_41_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \textbf{Figure 3. The resulting mean (solid line) and standard deviation
(shaded) normalized sizedistribution clusters for \(k\) = 5. The median
is shown as a dotted line.}

    \hypertarget{comparison-of-npf-indicators}{%
\subsection{Comparison of NPF
indicators}\label{comparison-of-npf-indicators}}

    To make a simple comparison between the three methods used to identify
NPF events (CPC-approach, integration method and clustering) the annual
cycle of the three proxies is shown below in Figure 4.

In the top panel the results from the absolute difference CPC method are
shown, and mid panel shows the difference between the CPCs. For some
instances one of the CPC's appears not have been in operation as it
showed zero values while the DMPS and the other CPC were in operation.
Therefore for these occasions where one CPC equals zero, the data is
excluded. In the midpanel the integration method results for a diameter
threshold diameter of 25 nm is shown, and indicated by the black dashed
line, and the shaded area shows the 10 and 90 percentiles of the data.
Note that this variable is plotted on the right y-axis. In the lower
panel, the annual cycles are plotted as the normalized occurrence of the
five cluster (in terms of the number of hours divided by total number of
hours each cluster is present each month) is shown. The clusters deemed
likely to represent NPF related size-distributions (cluster 1 and 2) are
highlighted.

From the results in the top panel the absolute difference between the
CPCs indicates a reasonable annual NPF cycle (and one similar to that of
cluster 1, 2 and 3). The same goes for taking the difference between the
CPCs (mid panel). However, the spread in the data is large in terms of
standard deviaions and percentiles.

It can be observed that the results from the integration method
(\(N_{D_P <X}/N_{tot}\)) in the mid panel display an annual cycle not
typically associated with NPF events at Zeppelin as shown in previous
studies (Dall'Osto et al.,2017; Tunved et al., 2013). Its annual trend
indicates a peak in the polar night months associated with Arctic haze
and therefore this method is discarded. Taking the ratio between the UF
CPC and normal CPC to identify NPF was also discarded (not shown here)
as taking ratios of very small numbers leads to uncertainty. Another
important conclusion is that the integration method was not successful
for the choice of thresholds equal to either 10,20 or 30 nm (only 25 nm
is shown).

Regarding the annual trends of the clusters in the lower panel of Figure
4, it can be observed that cluster 1, 2 and 3 exhibits annual trends
expected for NPF events. However, cluster 3 depict a similar trend
although it was discarded as NPF related due its very broad size
distribution (see Figure 3). The accumulation mode clusters (4,5)
however follow the expect annual cycle related to the Arctic Haze
phenomenon.

The rest of the project will focus on the clusters to ease comparision
with the previous results of Dall'Osto et al.~(2017).

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{16}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Input DFs, clusters, threshold = 10 nm for when to integrate}
\PY{n}{fu}\PY{o}{.}\PY{n}{plotNPFproxys}\PY{p}{(}\PY{n}{df\PYZus{}hourly\PYZus{}2010\PYZus{}2020\PYZus{}mean}\PY{p}{,}
                 \PY{n}{df\PYZus{}norm\PYZus{}clustered\PYZus{}1h\PYZus{}mean}\PY{p}{,}
                 \PY{n}{clusters}\PY{p}{,}\PY{n}{bin\PYZus{}cols}\PY{p}{,}\PY{l+m+mi}{25}\PY{p}{,}
                 \PY{n}{diameters}\PY{p}{,}\PY{n}{diameters\PYZus{}as\PYZus{}strings}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{ReportLovisaFinalDraft_files/ReportLovisaFinalDraft_45_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \textbf{Figure 4. Top panel: The annual cysle of the absolute difference
between the UF CPC and CPC 3010. Mid panel: The left axis shows the
annual cycle of the difference between the UF CPC and CPC 3010. The
right axis shows the results of integrating up to a certain threshold
diameter (here 10 nm was chosen). Lower panel: The annual cycle of size
distribution cluster 1-5.}

    The annual frequency distribution of the clusters is displayed in Figure
5 as a normalized stacked bar plot of clusters over the studied years
(2010-2020). During the summer months, cluster 1,2 and 3 dominate as
opposed to the polar night months where the accumulation mode clusters
dominate. This strengthens the assumption that cluster 4 and 5 are
indicators of Arctic haze and anthropogenic influence (Schmale \&
Baccarini, 2021; Tunved et al.~2013). It is evident that cluster 1 and 2
dominate during the summer months. Cluster 3 (not chosen to indicate
NPF) appears to follow a similar trend although it is present to higher
degree than especially cluster 1 in wintertime. However, cluster 3
remains excluded as an NPF proxy due to the shape of its size
distribution.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{17}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{fu}\PY{o}{.}\PY{n}{makeStackedPlot}\PY{p}{(}\PY{n}{df\PYZus{}norm\PYZus{}clustered\PYZus{}1h\PYZus{}mean}\PY{p}{,}\PY{n}{clusters}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{ReportLovisaFinalDraft_files/ReportLovisaFinalDraft_48_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \textbf{Figure 5. The annual frequency distribution of size
distributions cluster 1-5.}

    \hypertarget{trend-for-npf-events}{%
\subsection{Trend for NPF events}\label{trend-for-npf-events}}

    From the previous results, it can be concluded that the clustering
presents the best choice in comparison to the other methods to study
trends in NPF at Zeppelin. Potentially it could be interesting to study
the trend over the years for the different clusters. However, such
analysis excludes taking into account variation in NPF drivers such as
meteorological conditions or variations in NPF precursors or other
processes affecting the sources of these such as sea ice extent. We
normalized the cluster frequencies to account for data coverage so that
cluster occurrence would not be biased.

First the monthly occurrence needs to be determined for each year and
cluster. To ease handling of the dataframes,
\texttt{df\_clusters\_seqMonth\_T} is the transposed version of
\texttt{df\_clusters\_seqMonth} which contains one row for each
sequential month in the dataset, and columns for all the clusters where
the normalized occurrence of each cluster is given. The total cluster
count for each month is also given in a separate column.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{18}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{df\PYZus{}clusters\PYZus{}seqMonth}\PY{p}{,} \PY{n}{df\PYZus{}clusters\PYZus{}seqMonth\PYZus{}T} \PY{o}{=} \PY{n}{fu}\PY{o}{.}\PY{n}{prepareDFforTrendPlot}\PY{p}{(}\PY{n}{df\PYZus{}norm\PYZus{}clustered\PYZus{}1h\PYZus{}mean}\PY{p}{,}\PY{n}{clusters}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    The function \texttt{makeDFforTrend} takes the
\texttt{df\_clusters\_seqMonth\_T}, a list of the months of interest and
the cluster, and returns a normalized count dataframe for each month and
cluster. The months May to July where chosen as this is the time for
when the satalitte-retirieved chlorophyll has its annual peak (see Kei's
project).

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{19}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Define the period of interest in terms of months}
\PY{n}{MJJ\PYZus{}list} \PY{o}{=} \PY{p}{[}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{6}\PY{p}{,}\PY{l+m+mi}{7}\PY{p}{]}
\PY{n}{all\PYZus{}months\PYZus{}list} \PY{o}{=} \PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{4}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{6}\PY{p}{,}\PY{l+m+mi}{7}\PY{p}{,}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{9}\PY{p}{,}\PY{l+m+mi}{10}\PY{p}{,}\PY{l+m+mi}{11}\PY{p}{,}\PY{l+m+mi}{12}\PY{p}{]}

\PY{n}{df\PYZus{}norm\PYZus{}MJJ} \PY{o}{=} \PY{n}{fu}\PY{o}{.}\PY{n}{makeDFforTrend}\PY{p}{(}\PY{n}{df\PYZus{}clusters\PYZus{}seqMonth\PYZus{}T}\PY{p}{,}\PY{n}{MJJ\PYZus{}list}\PY{p}{,}\PY{n}{clusters}\PY{p}{)}
\PY{n}{df\PYZus{}norm\PYZus{}all} \PY{o}{=} \PY{n}{fu}\PY{o}{.}\PY{n}{makeDFforTrend}\PY{p}{(}\PY{n}{df\PYZus{}clusters\PYZus{}seqMonth\PYZus{}T}\PY{p}{,}\PY{n}{all\PYZus{}months\PYZus{}list}\PY{p}{,}\PY{n}{clusters}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    In Figure 6 below, the Theil-Sen slope and the uncertainty in the slope
(95\% confidence interval) is plotted which indicates the trend for the
months May, June and July for all clusters between the years 2010 and
2020. The Theil-Sen slope is a non-parametric method to discern trends
which is best suited for periods which do not contain any seasonality.
Non-parametric implies that it is robust towards non-normally
distributed data. By selecting for a specific season, there is no
influence from seasonality that would interfere with trend estimations,
i.e.~all autocorrelation is removed.

For cluster 1, 4 and 5 we observe a weak decreasing summertime trend of
about 1, 0.4 and 0.6\% per year. Cluster 2 and 3 has on the other
increased by 0.7 and 0.8\% yearly. At the beginning of the data set the
approximately 27\% of the summer observations consists of cluster 1 type
size distributions, and at the end of the period (110 months that ends
in 2010) about 16\%. Cluster 2 composes at the start 27\% of the
summertime clusters, wheras in the end it accounts for 38\% of the
observations.

Cluster 3 has increased its share of the summertime clusters from about
18\% to approximately 29\%. Cluster 4 and 5 consituted from the start
about 15 and 7\% of the observations whereas in the end, the estimated
slope suggests that their respective share remained constant (cluster 4)
or close to zero (cluster 5).

No obvious trend can be discerned for any of the clusters, although the
data display a varying degree of spread. The trends in satellite data
for chlorophyll and sea ice (Kei's work) were shown to be spatially
heterogenous for this period. To fully explain the results, additional
information is needed, such as airmass origin or trends in aerosol
precursors.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{20}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{fu}\PY{o}{.}\PY{n}{plotThielSen}\PY{p}{(}\PY{n}{df\PYZus{}norm\PYZus{}MJJ}\PY{p}{,} \PY{n}{clusters}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{May\PYZhy{}Jun\PYZhy{}Jul}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{ReportLovisaFinalDraft_files/ReportLovisaFinalDraft_56_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \textbf{Figure 6. The 2010-2020 May-June-July trend for cluster 1-5. The
x-axis indicates the consequtive months starting from the first
measurement point 2010. The (non-parametric) Thiel-Sen slope is used to
estimate the trend. The legend denotes the annual change in percentages
and the y = kx + m shows the estimated decrease per month (k) and the
initial estimated share of total normalized occurence (m).}

    \hypertarget{npf-relation-to-sea-ice-concentration}{%
\subsection{NPF relation to sea ice
concentration}\label{npf-relation-to-sea-ice-concentration}}

Our main aim was to make an attempt at reproducing the results from
Dall'Osto et al.~(2017) who put forward the hypothesis of an
anti-correlation between sea ice extent and NPF frequency, i.e.~that
decreasing sea ice in the Barents and Greenland Sea promotes NPF. We
investigated whether the anti-correlation holds true when more recent
data is used from the Zeppelin station. Dall'Osto et al.~(2017)
investigated the years 2000-2010 and this part of our study encompass
2010-2017 as there was an overlap between DMPS data and sea ice
satellite data for this period. Here, the annual sea ice concentration
data (Kei's work) in the Barents and Greenland Sea is used instead of
sea ice extent. We normalized the NPF observations to data coverage (in
order to remove this dependence) from cluster 1 and 2 and use the annual
sum of their frequency as those have been chosen as a proxy for NPF
events. We also investigated the cluster 1 and 2 and their correlation
to sea ice concentration in the region separately. First, the annual
occurrence of cluster 1 and 2 is computed and the sea ice concentration
data is loaded.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{21}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Compute the monthly and yearly normalized count for all clusters}
\PY{n}{df\PYZus{}monthly\PYZus{}cluster\PYZus{}count} \PY{o}{=} \PY{n}{df\PYZus{}norm\PYZus{}all}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{n}{deep} \PY{o}{=} \PY{k+kc}{True}\PY{p}{)}
\PY{n}{df\PYZus{}yearly\PYZus{}count\PYZus{}clusters} \PY{o}{=} \PY{n}{fu}\PY{o}{.}\PY{n}{DFAnnualCountNorm}\PY{p}{(}\PY{n}{df\PYZus{}norm\PYZus{}clustered\PYZus{}1h\PYZus{}mean}\PY{p}{,}\PY{n}{clusters}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Compute the total normlized count for cluster 1 and 2 by adding extra column and removing other clusters (=3,4,5)}
\PY{n}{monthly\PYZus{}cluster\PYZus{}count\PYZus{}12}\PY{p}{,} \PY{n}{df\PYZus{}yearly\PYZus{}cluster\PYZus{}count\PYZus{}12} \PY{o}{=} \PY{n}{fu}\PY{o}{.}\PY{n}{sumCluster12}\PY{p}{(}\PY{n}{df\PYZus{}monthly\PYZus{}cluster\PYZus{}count}\PY{p}{,}\PY{n}{df\PYZus{}yearly\PYZus{}count\PYZus{}clusters}\PY{p}{)}
\PY{n}{sea\PYZus{}ice\PYZus{}annual} \PY{o}{=} \PY{n}{fu}\PY{o}{.}\PY{n}{readSeaIcetoDF}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    Figure 7 below shows the correlation of the total annual normalized
cluster frequency (for cluster 1, 2 and their sum) for each year to sea
ice concentration. The results shown below give little confidence in the
hypothesis that NPF at Zeppelin is significantly anti-correlated with
sea ice concentration in the studied region between 2010-2017 (\(R^2\) =
0.31,0.34 and 0.37 respectively and \(p\) = 0.16, 0.13 and 0.11). The
p-value is the two-sided p-value for a hypothesis test whose null
hypothesis is that the slope is zero (no correlation). The calculated
p-values are enough to reject this null-hypothesis. At least not on a
reasonable confidence level. There are several explanations that are
possible for this. For example, the sample size is quite low, or there
is simply no correlation between sea ice concentration in the studied
region and NPF. This however that does not mean that changes in other
NPF drivers have not occurred simultaneously or in other regions which
have an effect on NPF drivers. Furthermore, it may be that the
1h-clusters we use here to study NPF related sizedistribution
frequencies do not capture the NPF events properly.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{22}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{fu}\PY{o}{.}\PY{n}{plotNPFvsSeaIce}\PY{p}{(}\PY{n}{sea\PYZus{}ice\PYZus{}annual}\PY{p}{,}\PY{n}{df\PYZus{}yearly\PYZus{}cluster\PYZus{}count\PYZus{}12}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{ReportLovisaFinalDraft_files/ReportLovisaFinalDraft_61_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \textbf{Figure 7. The 2010-2017 (normalized) total annual frequency of
cluster 1, 2 and their sum versus sea ice concentration in the Greenland
and Barents Sea (data from Kei's work).}

    \hypertarget{discussion}{%
\section{Discussion}\label{discussion}}

NPF is an import source of CCN in the Arctic where clouds exert a net
warming effect. However, the process driving NPF, and cloud droplet
response are complex (Birch et al., 2012). The main objective of this
project was to examine if the conclusions from Dall'Osto et al.~(2017)
holds true for more recent years i.e., that there is a causal
relationship between sea ice loss and NPF at the Zeppelin station. A
second objective was to investigate different methods for the
identification of NPF events.

To investigate the effect of sea ice melt on NPF frequency, the
identification of NPF events is crucial. Here, the K-means clustering
presented a decent option along with the CPC methods which, despite
large spread in the data in terms of standard deviaions and percentiles,
maybe could be used for validation of the K-means method. Manual
inspection of NPF events in the DMPS data is also advised to validate
the K-means approach. However, using unsupervised machine learning
provides little insight to the actual clustering procedure. Two metrics
were used to evaluate the performance of the clustering, but several
others are available which might affect the choice of \(k\). The Dunn
Index for example provides information about how compact and well
separated the clusters are.

In this work we calculated the inertia and average silhouette score, but
the results were hard to clearly draw conclusions on the optimal cluster
number from. Furthermore, increasing the cluster number decrease the
inertia and average Silhouette score. It could be that these in our case
were calculated wrong or, that DMPS data is not suitable for K-means
cluster over long time periods where there is risk that clusters
represent the overall seasonality instead (see Figure S1 and S2 in
Supplement). We also note that Dall'Osto et al.~(2017) and later
Dall'Osto et al.~(2018) at Villum Research Station, chose an optimal but
higher cluster number from their analysis, but condensed the number of
clusters by merging the clusters together manually by matching the size
distributions and time series, which might be beneficial.

We found no evidence of an anti-correlation between NPF and sea ice
concentration, despite a decrease of sea ice in the Barents Sea for the
years 2000-2017 (Kei's work). For the Greenland sea we observed no or
little decrease. A direct comparison is impaired by the different years
Dall'Osto et al.'s study and ours target. The relationship between NPF
and air mass origin is also something that needs to be accounted for, as
marine air masses that contribute to NPF may come from regions
unaffected by sea ice melt. Mixed and spatially heterogenous trends in
chlorophyll satellite data which is indicator of microbiological
activity (and source of NPF precursor gases) emphasizes the need for
back trajectory analysis in our work. The study of airmass back
trajectories is further encouraged as the majority of the airmasses that
resulted in NPF related size distributions in Dall'Osto et al.~(2017)
origined from the South and South-West, where we saw little or now
decrease in our sea ice satellite data from 2000-2017 (Kei's work).

To us it remains unclear if the results produced by Dall'Osto et
al.~(2017) used hourly clustered data or daily. We interpreted their
finding of NPF events (given in hours) and sea ice extent being
anti-correlated as a result of using hourly clustered data, and thus
applied a similar approach. However, NPF events tend to occur once a day
and therefore it might be beneficial to study the correlation of NPF
days to sea ice extent in our project. For \emph{k} = 5 clusters, the
daily median clusters looked similar in terms of shape (Figure S3 in
Supplement).

Even though the clustering method may not be optimal, the results
present some interesting features in terms of summertime trends. Cluster
3 has become increasingly frequent over the period, it could be
speculated (if we trust our cluster analysis) that cluster 3 would
provide an additional condensation sink which supress the MJJ NPF
(cluster 1, the most likely NPF related candidate, has experienced a
decreased occurrence for example). Studies on airmass origin and other
processes that might affect the composition and properties Arctic
submicron aerosols are needed to decipher the NPF controlling factors at
the Zeppelin Observatory.

    \hypertarget{conclusions-and-outlook}{%
\section{Conclusions and outlook}\label{conclusions-and-outlook}}

We observed weak trends for individual DMPS clusters, and no significant
anti-correlation of NPF to sea ice concentration in the Barents and
Greenland Sea (for cluster 1,2 and their sum). As Kei found that trends
are spatially heterogeneous for chlorophyll and sea ice concentration,
back trajectory analysis would provide valuable insight into the driving
forces behind NPF events at Zeppelin in a rapidly warming Arctic.

For future work a more careful cluster analyis is advised, for example
by using more clusters and merging the clusters. On the other hand, it
appears as clustering of longterm DMPS data may not be the best
approach, other methods are advised. Looking into to other changes in
the Arctic environment (airmass origin, biomass burning etc.) that has
affected the sizedistribution properties over the last twenty years
could also help with the task of identifying what drives NPF at
Zeppelin.

    \hypertarget{references}{%
\section{References}\label{references}}

Beck, L. J., Sarnela, N., Junninen, H., Hoppe, C. J. M., Garmash, O.,
Bianchi, F., et al.~(2021). Differing mechanisms of new particle
formation at two Arctic sites. Geophysical Research Letters, 48,
e2020GL091334. https://doi.org/10.1029/2020GL091334

Birch, C. E., Brooks, I. M., Tjernstr√∂m, M., Shupe, M. D., Mauritsen,
T., Sedlar, J., \ldots{} \& Leck, C. (2012). Modelling atmospheric
structure, cloud and their response to CCN in the central Arctic: ASCOS
case studies. Atmospheric Chemistry and Physics, 12(7), 3419-3435.

Dall¬¥Osto, M., Beddows, D., Tunved, P. et al.~Arctic sea ice melt leads
to atmospheric new particle formation. Sci Rep 7, 3318 (2017).
https://doi.org/10.1038/s41598-017-03328-1

Dall'Osto, M., Geels, C., Beddows, D. C. S., Boertmann, D., Lange, R.,
N√∏jgaard, J. K., et~al.~(2018). Regions of open water and melting sea
ice drive new particle formation in North East Greenland. Scientific
Reports, 8, 1--10. https://doi.org/10.1038/s41598-018-24426-8

Gal√≠, M., Devred, E., Babin, M., \& Levasseur, M. (2019). Decadal
increase in Arctic dimethylsulfide emission. Proceedings of the National
Academy of Sciences of the United States of America, 116(39),
19311--19317. https://doi.org/10.1073/pnas.1904378116

Gordon, H., Kirkby, J., Baltensperger, U., Bianchi, F., Breitenlechner,
M., Curtius, J., et~al.~(2017). Causes and importance of new parti- cle
formation in the present-day and preindustrial atmospheres. Journal of
Geophysical Research: Atmospheres, 122(16), 8739--8760.
https://doi.org/10.1002/2017JD026844

Mauritsen, T., Sedlar, J., Tjernstr√∂m, M., Leck, C., Martin, M., Shupe,
M., et~al.~(2011). An Arctic CCN-limited cloud-aerosol regime. Atmos-
pheric Chemistry and Physics, 11(1), 165--173.
https://doi.org/10.5194/acp-11-165-2011

Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B.,
Grisel, O., \ldots{} \& Duchesnay, E. (2011). Scikit-learn: Machine
learning in Python. the Journal of machine Learning research, 12,
2825-2830.

Perovich, D., Meier, W., Tschudi, M., Farrell, S., Hendricks, S.,
Gerland, S., \ldots{} \& Webster, M. (2018). Sea ice. NOAA Arctic Report
Card.

Schmale, J., \& Baccarini, A. (2021). Progress in unraveling atmospheric
new particle formation and growth across the Arctic. Geophysical
Research Letters, 48(14), e2021GL094198.

Seinfeld, J., \& Pandis, S. (2008). Atmospheric chemistry and physics.
1997. New York.

Tunved, P., Str√∂m, J. \& Krejci, R. Arctic aerosol life cycle: linking
aerosol size distributions observed between 2000 and 2010 with air mass
transport and precipitation at Zeppelin station, Ny-√Ölesund, Svalbard.
Atmos. Chem. Phys. 13, 3643--3660 (2013).

    \hypertarget{supplement}{%
\section{Supplement}\label{supplement}}

\hypertarget{comparision-between-clusters-and-seasonal-and-annual-cycle-of-dmps-data}{%
\subsection{Comparision between clusters and seasonal and annual cycle
of DMPS
data}\label{comparision-between-clusters-and-seasonal-and-annual-cycle-of-dmps-data}}

The clusters may represent the overall seasonal variation in the data
rather than actual features in terms of processes and sources leading to
a certain size distribution. Therefore, it could be interesting to plot
the normalized clustered 1h-data together with the seasonal median of
the normalized DMPS data (2010-2020), for both single months and
seasons. Figure S1 (top panel) shows the median and 10-90 percentiles of
the DMPS data (1h-resolution) for different seasons. Overall, all
seasonal medians display bimodality of varying extent. All seasons
appear to have a mode present around 30 nm. In DJF and MAM, the size
distribution peak in the accumulation mode. During DJF the peak occurs
for the largest particle sizes in comparison with the rest of the
seasons. It could also be noted that DJF and MAM are similar in terms of
shape of the distribution, although the magnitude may differ (not
visible as the data is normalized). In JJA on the other hand, the size
distribution peaks at around 30 nm and the distribution is clearly
bimodal for this season as well. For the autumn months (SON) the size
distribution peak shifts from the ultrafine to the accumulation mode,
but the contribution from the ultrafine particles is still visible.

In the bottom panel of Figure S1, the median clusters of the normalized
data are plotted together with the median normalized DMPS distributions.
As seen in Figure 3, all clusters display bimodality, just like the
seasonal median distributions.

Cluster 2 peaks at similar diameter as JJA, as opposed to the peak of
cluster 1 which occurs for the smallest particle sizes although it too
displays a tail into the accumulation mode. The accumulation mode
clusters (4 and 5) appear to qualitatively resemble to the median size
distributions of DJF and MAM. The overall shape of cluster 3 is not
similar any specific season although it on the left side bear similarity
to the lefthand side of JJA median and SON on the right side. Overall,
all clusters display bimodality as well as all seasons, and partly the
clusters agree well with the seasonal distributions. There is therefore
reason to believe that the clusters may be indicative of the overall
seasonality of the size distribution, but further investigation is
likely needed to conclude this.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{23}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Plot for seasons different seasons (DJF, MAM, JJA, SON)}
\PY{n}{fu}\PY{o}{.}\PY{n}{makeSeasonalSizeDistPlot}\PY{p}{(}\PY{n}{df\PYZus{}hourly\PYZus{}norm\PYZus{}dropped}\PY{p}{,}\PY{n}{diameters}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{:}\PY{o}{\PYZhy{}}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{,}\PY{n}{df\PYZus{}norm\PYZus{}clustered\PYZus{}1h\PYZus{}mean\PYZus{}median}\PY{p}{,}\PY{n}{clusters}\PY{p}{,}\PY{k+kc}{False}\PY{p}{,}\PY{k+kc}{True}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{ReportLovisaFinalDraft_files/ReportLovisaFinalDraft_67_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{ReportLovisaFinalDraft_files/ReportLovisaFinalDraft_67_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \textbf{Figure S1. The top panel shows the median clusters (dashed
lines) and 10,90 percentiles of the DMPS data (1h-resolution) for
different seasons between 2010-2020 (solid lines). The bottom panel
shows the median clusters togeteher with the median of the DMPS data
(1h-resolution) for different seasons between 2010-2020.}

    Figure S2 displays the same as Figure S1 but instead of seasons,
individual monthly median normalized size distributions are shown. The
upper panel is like the upper panel of Figure S1, but here more details
can be seen in the seasonal shift of the median size distribution.
Cluster 3 still displays no similarity to any of the monthly median
distributions, and cluster 4 and 5 are likely representing the Arctic
haze related episodes. In the lower panel of Figure S2, cluster 2
appears to be a good representative of the general summertime
distribution, but for cluster 1 the peak between 10 and 20 nm still
remains clearly distinguished from other monthly median distributions.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{24}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Plot for each month}
\PY{n}{fu}\PY{o}{.}\PY{n}{makeSeasonalSizeDistPlot}\PY{p}{(}\PY{n}{df\PYZus{}hourly\PYZus{}norm\PYZus{}dropped}\PY{p}{,}\PY{n}{diameters}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{:}\PY{o}{\PYZhy{}}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{,}\PY{n}{df\PYZus{}norm\PYZus{}clustered\PYZus{}1h\PYZus{}mean\PYZus{}median}\PY{p}{,}\PY{n}{clusters}\PY{p}{,}\PY{k+kc}{True}\PY{p}{,}\PY{k+kc}{False}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{ReportLovisaFinalDraft_files/ReportLovisaFinalDraft_70_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{ReportLovisaFinalDraft_files/ReportLovisaFinalDraft_70_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \textbf{Figure S2. The top panel shows the median clusters (dashed
lines) and 10,90 percentiles of the DMPS data (1h-resolution) for all
months between 2010-2020 (solid lines). The bottom panel shows the
median clusters togeteher with the median of the DMPS data
(1h-resolution) for all months between 2010-2020.}

    \hypertarget{daily-median-clusters}{%
\subsection{Daily median clusters}\label{daily-median-clusters}}

First the daily median data must be normalized before the clustering
takes place.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{25}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{df\PYZus{}daily\PYZus{}2010\PYZus{}2020\PYZus{}median} \PY{o}{=} \PY{n}{df\PYZus{}DMPS}\PY{o}{.}\PY{n}{resample}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{D}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{median}\PY{p}{(}\PY{p}{)}
\PY{c+c1}{\PYZsh{} drop NaN\PYZsq{}s that resample pads missing data with}
\PY{n}{df\PYZus{}daily\PYZus{}2010\PYZus{}2020\PYZus{}median} \PY{o}{=} \PY{n}{df\PYZus{}daily\PYZus{}2010\PYZus{}2020\PYZus{}median}\PY{o}{.}\PY{n}{dropna}\PY{p}{(}\PY{n}{how}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{all}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} 

\PY{c+c1}{\PYZsh{} Normalize the dataframe}
\PY{n}{df1}\PY{p}{,} \PY{n}{df\PYZus{}daily\PYZus{}2010\PYZus{}2020\PYZus{}median\PYZus{}norm} \PY{o}{=} \PY{n}{fu}\PY{o}{.}\PY{n}{create\PYZus{}normalised\PYZus{}df}\PY{p}{(}\PY{n}{df\PYZus{}daily\PYZus{}2010\PYZus{}2020\PYZus{}median}\PY{p}{)}
\PY{c+c1}{\PYZsh{} Cluster the dataframe }
\PY{n}{avSilDaily}\PY{p}{,} \PY{n}{inertaDaily}\PY{p}{,} \PY{n}{df\PYZus{}norm\PYZus{}clustered\PYZus{}median} \PY{o}{=} \PY{n}{fu}\PY{o}{.}\PY{n}{perform\PYZus{}clustering}\PY{p}{(}\PY{n}{df\PYZus{}daily\PYZus{}2010\PYZus{}2020\PYZus{}median\PYZus{}norm}\PY{p}{,} \PY{n}{n\PYZus{}clusters}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    Figure S3 displays a comprision of the daily median clusters
(median+10-90 percentile) and the median of the 1h-clusters. The peak is
shifted to somewhat larger sizes for the smallest 1h-clusters, otherwise
they are similar in terms of shape. However the cluster number was not
optimized for daily clusters.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{26}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{fu}\PY{o}{.}\PY{n}{plotMedianClusters}\PY{p}{(}\PY{n}{df\PYZus{}norm\PYZus{}clustered\PYZus{}median}\PY{p}{,}\PY{n}{diameters}\PY{p}{,}\PY{n}{n\PYZus{}clusters}\PY{p}{,}\PY{n}{clusters}\PY{p}{,}\PY{n}{df\PYZus{}norm\PYZus{}clustered\PYZus{}1h\PYZus{}mean\PYZus{}median}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{ReportLovisaFinalDraft_files/ReportLovisaFinalDraft_75_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \textbf{Figure S3. Median 1h cluster indicated as dotted lines and
median daily clusters as solid lines. Shaded regions show the 10,90
percentile}


    % Add a bibliography block to the postdoc
    
    
    
\end{document}
